{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Usage of RL for Stowage Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Firstly various modules are imported (including agent classes, environment classes, a plotting unit and a logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "module_path = str(os.getcwd())+'\\\\out\\\\'\n",
    "\n",
    "from env import roroDeck\n",
    "from agent import sarsa, tdq, dqn\n",
    "from analysis import *\n",
    "from analysis.algorithms import *\n",
    "from analysis.evaluator import Evaluator\n",
    "from analysis.loggingUnit import LoggingBase\n",
    "\n",
    "\n",
    "from agent.tdq import TDQLearning\n",
    "from agent.sarsa import SARSA\n",
    "from agent.dqn import DQLearningAgent\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a model and show input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set path to saved prototype\n",
    "See comments for examples. The path will depend on the loaction of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set relative path to loacation where Training.iynb will safe files:\n",
    "path = LoggingBase(prepare_training = False).module_path\n",
    "\n",
    "# Set relative path to other loacation, e.g. submitted prototypes\n",
    "path = '\\\\'.join(path.split('\\\\')[0:-4])\n",
    "\n",
    "print('Relative path is set to:\\n'+path+'\\n')\n",
    "\n",
    "#add specific location to file. For example:\n",
    "path = path + \"20201118\\\\1927\\\\1927SARSA_L8-R12.p\"\n",
    "print('Will load prototype saved at:\\n'+path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set environment according to input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass loading list by setting RoRo-deck environment th argument vehicle_data\n",
    "# For example: roroDeck.RoRoDeck(vehicle_data=loading_list_1)\n",
    "\n",
    "loading_list_1 = np.array([[ 0,  1,  2,  3,  4,  5,  6],\n",
    "                           [ 5,  5, -1, -1,  2,  2,  2],\n",
    "                           [ 1,  1,  0,  0,  1,  1,  1],\n",
    "                           [ 1,  2,  1,  2,  2,  1,  2],\n",
    "                           [ 2,  3,  2,  3,  2,  2,  3],\n",
    "                           [ 0,  0,  0,  0,  1,  0,  0]])\n",
    "\n",
    "loading_list_2 = np.array([[0,   1,  2,  3,  4], \n",
    "                           [5,   5, -1, -1,  2], \n",
    "                           [1,   1,  0,  0,  1], \n",
    "                           [1,   2,  1,  2,  2], \n",
    "                           [3,   4,  2,  3,  2], \n",
    "                           [0,   0,  0,  0,  1]]) \n",
    "\n",
    "\n",
    "# Environment dimensions must fit to the prototype\n",
    "env = roroDeck.RoRoDeck(lanes=8, rows=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create agent, bind environment and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent = tdq.TDQLearning(env,path)\n",
    "agent = sarsa.SARSA(env,path)\n",
    "#agent = dqn.DQLearningAgent(env,path)\n",
    "\n",
    "#Add specific path\n",
    "agent.load_model(path)\n",
    "\n",
    "env = agent.env\n",
    "evaluator = Evaluator(env.vehicle_data, env.grid)\n",
    "\n",
    "if type(agent) is not type(dqn.DQLearningAgent(env,path)):\n",
    "    for info in agent.q_table[\"ModelParam\"]:\n",
    "        print(info +': '+ str(agent.q_table[\"ModelParam\"][info]))\n",
    "else:\n",
    "    print(agent.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show best stowage plan the agent found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "agent.execute(env)\n",
    "evaluation = evaluator.evaluate(env.get_stowage_plan())\n",
    "env.render()\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the loading sequence which constructed this stowage plan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.loading_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Interface\n",
    "\n",
    "#### Construct a stowage plan sequentially\n",
    "\n",
    "Example of a an human-agent interaction:\n",
    "The agent shows the predictions for each action in a given state and recommends the best one.\n",
    "If the environment is set to deterministic behaviour the stowage plan above is reconstructed if all recommendations are obeyed\n",
    "\n",
    "Usage (Type the following on the Keyboard and press Enter):\n",
    "\n",
    "0,1,2 &nbsp; &nbsp; &nbsp; &nbsp; *number from the list of possible actions*\n",
    "\n",
    "r &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; *show the current state of the RORO-deck*\n",
    "\n",
    "b &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*follow the best action*\n",
    "\n",
    "f &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*stop interaction by only following the recommendations of agent*\n",
    "\n",
    "q &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*quit the execution*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "done = False\n",
    "counter = 1\n",
    "while not done:\n",
    "    print(\"\\n\"+str(counter)+\". Vehicle\\nPossible Actions for Lane \"+str(env.current_Lane)\n",
    "          +\"\\n\"+str(env.possible_actions))\n",
    "    source = []\n",
    "    for action in env.possible_actions:\n",
    "        source += [round(float(agent.predict(state,action)),2)]\n",
    "    best_action = agent.max_action(state,env.possible_actions)\n",
    "    \n",
    "    #print(env.possible_actions)\n",
    "    #source = DQN_agent.q_eval.predict(state[np.newaxis, :])\n",
    "    #best_action = DQN_agent.maxAction(state,env.possible_actions)\n",
    "    #print(\"Prediction of Agent:\\n\"+str(source[0][env.possible_actions]))\n",
    "    print(\"Prediction of Agent:\\n\"+str(source))\n",
    "    print(\"--> Choose: \"+str(best_action))\n",
    "    action = input() \n",
    "    try:\n",
    "        action = int(action)\n",
    "        if int(action) in env.possible_actions:\n",
    "            state, reward, done, info = env.step(int(action))\n",
    "            counter += 1            \n",
    "    except:\n",
    "        if action == 'b':\n",
    "            state, reward, done, info = env.step(int(best_action))\n",
    "            counter += 1\n",
    "        elif action == 'f':\n",
    "            #DQN_agent.execute(env)\n",
    "            agent.execute(env)\n",
    "            #agent.execute()\n",
    "            break\n",
    "        elif action == 'q':\n",
    "            print(\"Quit execution mode\")\n",
    "            break\n",
    "        elif action == 'r':\n",
    "            env.render()\n",
    "env.render()\n",
    "print(\"\\n\\n\")\n",
    "evaluation = evaluator.evaluate(env.get_stowage_plan())\n",
    "print(evaluation)\n",
    "print(\"\\n\\n\")\n",
    "print(env.loading_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
