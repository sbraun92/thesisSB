{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Evaluation of Model DQLearning_L08-R12-L1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "module_path = str(os.getcwd())+'\\\\out\\\\'\n",
    "\n",
    "module_path = str(os.path.dirname(os.getcwd()))+'\\\\output\\\\'\n",
    "\n",
    "from env import roroDeck\n",
    "from agent import sarsa, tdq, dqn\n",
    "from analysis import *\n",
    "from analysis.algorithms import *\n",
    "from analysis import evaluator as evm\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"whitegrid\")\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams.update({'text.color' : \"black\",\n",
    "                     'axes.labelcolor' : \"black\"})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparation\n",
    "Construct a set with **400** (`n_evaluations`) unique **random** stowage plan evaluations.\n",
    "These evaluations are based on randomly generated stowage plans by the RORO-deck environment.\n",
    "\n",
    "If the evaluation of a randomly generated stowage plan is equivalent to another evaluation within the set this stowage plan is discarded.\n",
    "If the this size is not reached within **50_000** (`time_out`) iterations than this procedure is stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_evaluations = 400\n",
    "time_out = 50_000\n",
    "start=datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a model and print the training parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_list_1 =  np.array([[ 0,  1,  2,  3,  4,  5,  6],\n",
    "                           [ 5,  5, -1, -1,  2,  2,  2],\n",
    "                           [ 1,  1,  0,  0,  1,  1,  1],\n",
    "                           [ 1,  2,  1,  2,  2,  1,  2],\n",
    "                           [ 2,  3,  2,  3,  2,  2,  3],\n",
    "                           [ 0,  0,  0,  0,  1,  0,  0]])\n",
    "\n",
    "loading_list_2 = np.array([[0, 1, 2, 3, 4], \n",
    "                         [5, 5, -1, -1, 2], \n",
    "                         [1, 1, 0, 0, 1], \n",
    "                         [1, 2, 1, 2, 2], \n",
    "                         [3, 4, 2, 3, 2], \n",
    "                         [0, 0, 0, 0, 1]]) \n",
    "\n",
    "# Note that loading_list_0 is the default\n",
    "env = roroDeck.RoRoDeck(lanes=8, rows=12, stochastic=True, vehicle_data=loading_list_1)\n",
    "evaluator = evm.Evaluator(env.vehicle_data, env.grid)\n",
    "\n",
    "agent = dqn.DQLearningAgent(env, module_path)\n",
    "\n",
    "agent.load_model(module_path+\"DQLearning\\\\L08-R12-L1\\\\DQLearning_L08-R12-L1.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_sorted_random_stowage_plans()` constructs the random set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_sorted_random_stowage_plans():\n",
    "    random_stowage_plans = set()\n",
    "    i = 0\n",
    "    \n",
    "    while len(random_stowage_plans) < n_evaluations and i < time_out:\n",
    "        done = False\n",
    "        env.reset()\n",
    "        while not done:\n",
    "            state, reward, done, info = env.step(env.action_space_sample())\n",
    "        evaluation = evaluator.evaluate(env.get_stowage_plan())\n",
    "        random_stowage_plans.add(evaluation)\n",
    "        i+=1\n",
    "        if i%500 == 0:\n",
    "            print(str(i)\n",
    "                  + ' of {}\\t unique stowage plan evaluations:\\t'.format(time_out)\n",
    "                  + str(len(random_stowage_plans)))\n",
    "    if i == time_out:\n",
    "        print('\\n\\nWARNING:\\tCould not construct {} evaluations.'.format(n_evaluations))\n",
    "        print('\\t\\tActual number is {}'.format(len(random_stowage_plans)))\n",
    "\n",
    "    random_stowage_plans = list(random_stowage_plans)\n",
    "    random_stowage_plans.sort()\n",
    "    return random_stowage_plans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`valuate model()` evaluates ranks. Three metrices may be calculated by this:\n",
    "\n",
    "- deterministic rank ie. the stowage plan if the environment is set to deterministic\n",
    "- avg. ranks 95% and 99%\n",
    "*(Construct **50** stowage plans with the model and some randomness, report mean and standard deviation)*\n",
    "- lowest ranks from the avg. ranks 95% and 99%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valuate_model(env_local, plans, n=50, info=False):\n",
    "    performance = []\n",
    "    for i in range(n):\n",
    "        env_local.reset()\n",
    "        agent.execute()\n",
    "        evaluation = evaluator.evaluate(env_local.get_stowage_plan())\n",
    "        plans_val = plans.copy()\n",
    "        plans_val.append(evaluation)\n",
    "        plans_val = list(dict.fromkeys(plans_val))\n",
    "        \n",
    "        plans_val.sort()\n",
    "       \n",
    "        if len(plans_val) == len(plans)+1:\n",
    "            plans_val = plans_val[1:]\n",
    "\n",
    "        \n",
    "        #at which postion is the stowage plan of the agent. (maximal performance 100%)\n",
    "        for ix,i in enumerate(plans_val):\n",
    "            if i == evaluation:\n",
    "                if info:\n",
    "                    print(str(ix+1)+\". Position of \"+str(len(plans_val))+ \\\n",
    "                      \"\\t Performance of model: \"+str((ix+1)/(len(plans_val))))\n",
    "                performance += [(ix+1)/(len(plans_val))]\n",
    "                break\n",
    "        \n",
    "    return np.array(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create Random Stowage Plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_plans = get_sorted_random_stowage_plans()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Rank Deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "env.p = 1.\n",
    "performance = valuate_model(env,random_plans, n=1, info=False)\n",
    "print('Rank deterministic: ',performance[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Rank with p=99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.p = 0.99\n",
    "performance99 = valuate_model(env,random_plans, n=100, info=False)\n",
    "print('Rank at 99%:\\nMean:\\t',performance99.mean(),'\\nStd.:\\t',performance99.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Rank with p=95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.p = 0.95\n",
    "performance95 = valuate_model(env,random_plans, n=100, info=False)\n",
    "print('Rank at 95%:\\nMean:\\t',performance95.mean(),'\\nStd.:\\t',performance95.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Minimal Rank with p=99% and p=95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lowest Rank\\nat 99%:\\t',performance99.min(),'\\nat 95%:\\t',performance95.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Critical p with Mann-Whitney-U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ranksums\n",
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce `env.p` from 90% to 0% and do the Mann-Whitney-U test. Stop when critical p is reached"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.linspace(0.98,0,71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = random_plans.copy()\n",
    "random_ranks_prev, agent_ranks_prev = None,None\n",
    "for ix, temperature in enumerate(a):\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('Process {}%\\t\\tCurrent env.p={}'.format((round(ix*100/len(a),2)),(round(temperature,4))))\n",
    "\n",
    "    env.stochastic= True\n",
    "    env.p = temperature\n",
    "    best_sp = []\n",
    "\n",
    "    while len(best_sp)<100:\n",
    "        env.reset()\n",
    "        agent.execute()\n",
    "        evaluation = evaluator.evaluate(env.get_stowage_plan())\n",
    "        if evaluation not in random:\n",
    "            best_sp += [evaluation]\n",
    "            \n",
    "    all_ranks = random + best_sp\n",
    "    all_ranks.sort()\n",
    "    \n",
    "    random_ranks = []\n",
    "    agent_ranks = []\n",
    "    for rank, i in enumerate(all_ranks):\n",
    "        if i in best_sp:\n",
    "            agent_ranks+=[rank]\n",
    "        else:\n",
    "            random_ranks+=[rank]\n",
    "        \n",
    "    agent_ranks = np.array(agent_ranks)\n",
    "    random_ranks = np.array(random_ranks)\n",
    "    \n",
    "    _,p = mannwhitneyu(random_ranks, agent_ranks, alternative='two-sided')\n",
    "    print('\\t\\t\\tMann-Whitney-U p_value:',str(round(p,9)))\n",
    "    if p > 0.01:\n",
    "        print('STOP -> critical p identified\\n')\n",
    "        break\n",
    "    random_ranks_prev = random_ranks\n",
    "    agent_ranks_prev = agent_ranks\n",
    "    \n",
    "    \n",
    "_,p = mannwhitneyu(random_ranks, agent_ranks, alternative='two-sided')\n",
    "print('The test was not significant anymore at env.p=',temperature)\n",
    "print(mannwhitneyu(random_ranks, agent_ranks, alternative='two-sided'))\n",
    "print('The p-value is higher than 1%')\n",
    "print('\\nMann-Whitney-U test statistic of last significant p')\n",
    "print(mannwhitneyu(random_ranks_prev, agent_ranks_prev, alternative='two-sided'))\n",
    "print('Statistic of the Wilcoxcon-Ranksum Test:')\n",
    "print(ranksums(random_ranks_prev,agent_ranks_prev))\n",
    "print('*'*40)\n",
    "print('Critical p:\\t:',a[ix-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = str(os.getcwd())+'\\\\out\\\\'\n",
    "os.makedirs(module_path, exist_ok=True)\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "plt.rcParams.update({'text.color' : \"black\",\n",
    "                     'axes.labelcolor' : \"black\"})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Rank Mean over env.p \n",
    "Visualise the mean ranks for different level of env.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "std = []\n",
    "x = np.linspace(0,1,21)\n",
    "for ix,i in enumerate(x):\n",
    "    print('Process {}%'.format(round(ix*100/len(x),4)))\n",
    "    env.p = i\n",
    "    performance = valuate_model(env,random_plans, n=50)\n",
    "    means += [performance.mean()]\n",
    "    std += [performance.std()]\n",
    "\n",
    "fig = plt.figure(figsize=(5.1, 2.2))\n",
    "\n",
    "plt.plot(x, means)\n",
    "plt.xlabel(\"env.p\")\n",
    "plt.ylabel(\"Rank (Mean of n=50)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Rank distribution at critical env.p\n",
    "Visualise critical p Rank distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw = 50\n",
    "\n",
    "fig = plt.figure(figsize=(5.1, 2.2))\n",
    "\n",
    "fig.tight_layout()\n",
    "gs = fig.add_gridspec(4, 3)\n",
    "\n",
    "fi_ax1 = fig.add_subplot(gs[0:3, :])\n",
    "fi_ax2 = fig.add_subplot(gs[3, :],sharex=fi_ax1)\n",
    "\n",
    "\n",
    "plt.setp(fi_ax1.get_xticklabels(), visible=False)\n",
    "plt.setp(fi_ax2.get_xticklabels(), visible=True)\n",
    "\n",
    "\n",
    "ax = sns.kdeplot(np.array(agent_ranks), bw=bw, clip=[0,len(all_ranks)],kernel='epa', ax=fi_ax1,label='Agent')\n",
    "ax = sns.kdeplot(np.array(random_ranks),ax=ax , bw=bw, clip=[0,len(all_ranks)],kernel='epa',label='Random')\n",
    "\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, box.y0 +0.5* box.height), fontsize=11*(1/0.9))\n",
    "\n",
    "ax = sns.stripplot(np.array(agent_ranks),alpha=0.5, ax = fi_ax2,label='Agent')\n",
    "ax = sns.stripplot(np.array(random_ranks),alpha=0.35, ax = ax, color=sns.color_palette(\"deep\")[1],label='Random')\n",
    "ax.set_xlim(-bw, len(all_ranks)+bw)\n",
    "\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "\n",
    "    \n",
    "fi_ax1.set(ylabel='Density')\n",
    "fi_ax2.set(xlabel='Ranks')\n",
    "\n",
    "plt.savefig(module_path + '\\\\denisity_p'+str(round(temperature,4))+'prozent_bw50.pdf', dpi=600, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('This Notebook took:',datetime.now()-start,'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
