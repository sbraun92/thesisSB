{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Usage of RL for Stowage Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Firstly various modules are imported (including agent classes, environment classes, a plotting unit and a logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "module_path = str(os.getcwd())+'\\\\out\\\\'\n",
    "\n",
    "from env import roroDeck\n",
    "from agent import sarsa, tdq, dqn\n",
    "from analysis import *\n",
    "from analysis.algorithms import *\n",
    "from analysis.evaluator import Evaluator\n",
    "from analysis.loggingUnit import LoggingBase\n",
    "\n",
    "\n",
    "from agent.tdq import TDQLearning\n",
    "from agent.sarsa import SARSA\n",
    "from agent.dqn import DQLearningAgent\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a model and show input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set path to saved prototype\n",
    "See comments for examples. The path will depend on the loaction of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative path is set to:\n",
      "C:\\Users\\braun\\Documents\n",
      "\n",
      "Will load prototype saved at:\n",
      "C:\\Users\\braun\\Documents\\Masterarbeit\\output\\DQLearning\\L08-R12-L0\\DQLearning_L08-R12-L0.h5\n"
     ]
    }
   ],
   "source": [
    "# Set relative path to loacation where Training.iynb will safe files:\n",
    "path = LoggingBase(prepare_training = False).module_path\n",
    "\n",
    "# Set relative path to other loacation, e.g. submitted prototypes\n",
    "path = '\\\\'.join(path.split('\\\\')[0:-4])\n",
    "\n",
    "print('Relative path is set to:\\n'+path+'\\n')\n",
    "\n",
    "#add specific location to file. For example:\n",
    "#path = path + \"20201118\\\\1927\\\\1927SARSA_L8-R12.p\"\n",
    "path = path +\"\\\\Masterarbeit\\\\output\\\\DQLearning\\\\L08-R12-L0\\\\DQLearning_L08-R12-L0.h5\"\n",
    "print('Will load prototype saved at:\\n'+path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set environment according to input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass loading list by setting RoRo-deck environment vehicle_data\n",
    "\n",
    "loading_list_1 = np.array([[ 0,  1,  2,  3,  4],\n",
    "                           [ 5,  5, -1, -1,  2],\n",
    "                           [ 1,  1,  0,  0,  1],\n",
    "                           [ 1,  2,  1,  2,  2],\n",
    "                           [ 3,  4,  2,  3,  2],\n",
    "                           [ 0,  0,  0,  0,  1]])\n",
    "\n",
    "loading_list_2 = np.array([[ 0,  1,  2,  3,  4,  5,  6],\n",
    "                           [ 5,  5, -1, -1,  2,  2,  2],\n",
    "                           [ 1,  1,  0,  0,  1,  1,  1],\n",
    "                           [ 1,  2,  1,  2,  2,  1,  2],\n",
    "                           [ 2,  3,  2,  3,  2,  2,  3],\n",
    "                           [ 0,  0,  0,  0,  1,  0,  0]])\n",
    "\n",
    "\n",
    "# Environment dimensions must fit to the prototype\n",
    "env = roroDeck.RoRoDeck(lanes=8, rows=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create agent, bind environment and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DQ-Agent:\t\t ALPHA: 0.0005 \n",
      "\t\t\t GAMMA: 0.999\n",
      "\t\t\t Replay Buffer Memory Size: 1000000\n",
      "\t\t\t Model name: None\n",
      "\t\t\t Epsilon Decrement: 0.9996\n",
      "\t\t\t Batch Size: 32\n",
      "\t\t\t Iterations: 12000\n",
      "\t\t\t Pretraining End Episode: 10000\n",
      " Information on Q-Network\n",
      "********************************************************************************\n",
      "NN has \n",
      " \t\t\t\t\t2 layers with relu activation \n",
      "\t\t\t\t\t0.001 L2-activity regularisation in each layer\n",
      "\t\t\t\t\tAdam-Optimiser with learning rate 0.0005 \n",
      "\t\t\t\t\tMean Squared Error- loss function\n",
      "********************************************************************************\n",
      "\n",
      " Information on target Q-Network (Identical with Q-Network)\n",
      "********************************************************************************\n",
      "NN has \n",
      " \t\t\t\t\t2 layers with relu activation \n",
      "\t\t\t\t\t0.001 L2-activity regularisation in each layer\n",
      "\t\t\t\t\tAdam-Optimiser with learning rate 0.0005 \n",
      "\t\t\t\t\tMean Squared Error- loss function\n",
      "********************************************************************************\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               3328      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 20,485\n",
      "Trainable params: 20,485\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#agent = tdq.TDQLearning(env,path)\n",
    "#agent = sarsa.SARSA(env,path)\n",
    "agent = dqn.DQLearningAgent(env,path)\n",
    "\n",
    "#Add specific path\n",
    "agent.load_model(path)\n",
    "\n",
    "env = agent.env\n",
    "evaluator = Evaluator(env.vehicle_data, env.grid)\n",
    "\n",
    "if type(agent) is not type(dqn.DQLearningAgent(env,path)):\n",
    "    for info in agent.q_table[\"ModelParam\"]:\n",
    "        print(info +': '+ str(agent.q_table[\"ModelParam\"][info]))\n",
    "else:\n",
    "    print(agent.info)\n",
    "    print(agent.q_eval.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show best stowage plan the agent found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------Loading Sequence----------------------------------------------------------------\n",
      "X\tX\tX\tX\tX\tX\tX\tX\t\n",
      "\n",
      "X\tX\tX\t1\t2\tX\tX\tX\t\n",
      "\n",
      "X\tX\t3\t1\t2\t4\tX\tX\t\n",
      "\n",
      "X\t5\t3\t6\t2\t4\t7\tX\t\n",
      "\n",
      "8\t5\t9\t6\t10\t4\t7\t11\t\n",
      "\n",
      "8\t12\t9\t13\t10\t14\t7\t11\t\n",
      "\n",
      "15\t12\t16\t13\t10\t14\t17\t11\t\n",
      "\n",
      "15\t18\t16\t19\t20\t21\t17\t22\t\n",
      "\n",
      "23\t18\t24\t19\t20\t21\t17\t22\t\n",
      "\n",
      "23\t25\t24\t26\t27\t28\t29\t30\t\n",
      "\n",
      "23\t25\t31\t26\t27\t28\t29\t30\t\n",
      "\n",
      "-\t-\t31\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-----------VehicleType--------------------------------------------------------------------\n",
      "X\tX\tX\tX\tX\tX\tX\tX\t\n",
      "\n",
      "X\tX\tX\t0\t1\tX\tX\tX\t\n",
      "\n",
      "X\tX\t0\t0\t1\t1\tX\tX\t\n",
      "\n",
      "X\t0\t0\t0\t1\t1\t1\tX\t\n",
      "\n",
      "4\t0\t0\t0\t1\t1\t1\t1\t\n",
      "\n",
      "4\t2\t0\t2\t1\t2\t1\t1\t\n",
      "\n",
      "4\t2\t2\t2\t1\t2\t3\t1\t\n",
      "\n",
      "4\t2\t2\t2\t2\t2\t3\t2\t\n",
      "\n",
      "3\t2\t2\t2\t2\t2\t3\t2\t\n",
      "\n",
      "3\t2\t2\t2\t2\t2\t2\t2\t\n",
      "\n",
      "3\t2\t2\t2\t2\t2\t2\t2\t\n",
      "\n",
      "-\t-\t2\t-\t-\t-\t-\t-\t\n",
      "\n",
      "-----------Destination--------------------------------------------------------------------\n",
      "X\tX\tX\tX\tX\tX\tX\tX\t\n",
      "\n",
      "X\tX\tX\t1\t2\tX\tX\tX\t\n",
      "\n",
      "X\tX\t1\t1\t2\t2\tX\tX\t\n",
      "\n",
      "X\t1\t1\t1\t2\t2\t2\tX\t\n",
      "\n",
      "2\t1\t1\t1\t2\t2\t2\t2\t\n",
      "\n",
      "2\t1\t1\t1\t2\t1\t2\t2\t\n",
      "\n",
      "2\t1\t1\t1\t2\t1\t2\t2\t\n",
      "\n",
      "2\t1\t1\t1\t1\t1\t2\t1\t\n",
      "\n",
      "2\t1\t1\t1\t1\t1\t2\t1\t\n",
      "\n",
      "2\t1\t1\t1\t1\t1\t1\t1\t\n",
      "\n",
      "2\t1\t1\t1\t1\t1\t1\t1\t\n",
      "\n",
      "-\t-\t1\t-\t-\t-\t-\t-\t\n",
      "\n",
      "\n",
      "\n",
      "********************************************************************************\n",
      "Evaluation of Stowage Plan\n",
      "Mandatory Cargo Loaded:\t\t 1.0\n",
      "Number of Shifts:\t\t 0.0\n",
      "Space Utilisation:\t\t 0.9078947368421053\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "agent.execute(env)\n",
    "evaluation = evaluator.evaluate(env.get_stowage_plan())\n",
    "env.render()\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the loading sequence which constructed this stowage plan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Sequence of RORO-Deck (Lanes: 8 Rows: 12)\n",
      "\n",
      "1. Load Vehicle Type \t 0 \t in Lane: \t 3 \t Row: \t 1 \n",
      "2. Load Vehicle Type \t 1 \t in Lane: \t 4 \t Row: \t 1 \n",
      "3. Load Vehicle Type \t 0 \t in Lane: \t 2 \t Row: \t 2 \n",
      "4. Load Vehicle Type \t 1 \t in Lane: \t 5 \t Row: \t 2 \n",
      "5. Load Vehicle Type \t 0 \t in Lane: \t 1 \t Row: \t 3 \n",
      "6. Load Vehicle Type \t 0 \t in Lane: \t 3 \t Row: \t 3 \n",
      "7. Load Vehicle Type \t 1 \t in Lane: \t 6 \t Row: \t 3 \n",
      "8. Load Vehicle Type \t 4 \t in Lane: \t 0 \t Row: \t 4 \n",
      "9. Load Vehicle Type \t 0 \t in Lane: \t 2 \t Row: \t 4 \n",
      "10. Load Vehicle Type \t 1 \t in Lane: \t 4 \t Row: \t 4 \n",
      "11. Load Vehicle Type \t 1 \t in Lane: \t 7 \t Row: \t 4 \n",
      "12. Load Vehicle Type \t 2 \t in Lane: \t 1 \t Row: \t 5 \n",
      "13. Load Vehicle Type \t 2 \t in Lane: \t 3 \t Row: \t 5 \n",
      "14. Load Vehicle Type \t 2 \t in Lane: \t 5 \t Row: \t 5 \n",
      "15. Load Vehicle Type \t 4 \t in Lane: \t 0 \t Row: \t 6 \n",
      "16. Load Vehicle Type \t 2 \t in Lane: \t 2 \t Row: \t 6 \n",
      "17. Load Vehicle Type \t 3 \t in Lane: \t 6 \t Row: \t 6 \n",
      "18. Load Vehicle Type \t 2 \t in Lane: \t 1 \t Row: \t 7 \n",
      "19. Load Vehicle Type \t 2 \t in Lane: \t 3 \t Row: \t 7 \n",
      "20. Load Vehicle Type \t 2 \t in Lane: \t 4 \t Row: \t 7 \n",
      "21. Load Vehicle Type \t 2 \t in Lane: \t 5 \t Row: \t 7 \n",
      "22. Load Vehicle Type \t 2 \t in Lane: \t 7 \t Row: \t 7 \n",
      "23. Load Vehicle Type \t 3 \t in Lane: \t 0 \t Row: \t 8 \n",
      "24. Load Vehicle Type \t 2 \t in Lane: \t 2 \t Row: \t 8 \n",
      "25. Load Vehicle Type \t 2 \t in Lane: \t 1 \t Row: \t 9 \n",
      "26. Load Vehicle Type \t 2 \t in Lane: \t 3 \t Row: \t 9 \n",
      "27. Load Vehicle Type \t 2 \t in Lane: \t 4 \t Row: \t 9 \n",
      "28. Load Vehicle Type \t 2 \t in Lane: \t 5 \t Row: \t 9 \n",
      "29. Load Vehicle Type \t 2 \t in Lane: \t 6 \t Row: \t 9 \n",
      "30. Load Vehicle Type \t 2 \t in Lane: \t 7 \t Row: \t 9 \n",
      "31. Load Vehicle Type \t 2 \t in Lane: \t 2 \t Row: \t 10 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(env.loading_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Interface\n",
    "\n",
    "#### Construct a stowage plan sequentially\n",
    "\n",
    "Example of a an human-agent interaction:\n",
    "The agent shows the predictions for each action in a given state and recommends the best one.\n",
    "If the environment is set to deterministic behaviour the stowage plan above is reconstructed if all recommendations are obeyed\n",
    "\n",
    "Usage (Type the following on the Keyboard and press Enter):\n",
    "\n",
    "0,1,2 &nbsp; &nbsp; &nbsp; &nbsp; *number from the list of possible actions*\n",
    "\n",
    "r &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; *show the current state of the RORO-deck*\n",
    "\n",
    "b &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*follow the best action*\n",
    "\n",
    "f &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*stop interaction by only following the recommendations of agent*\n",
    "\n",
    "q &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*quit the execution*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Vehicle\n",
      "Possible Actions for Lane 3\n",
      "[0 1 2 3]\n",
      "Prediction of Agent:\n",
      "[8.42, 3.43, 2.35, 2.06]\n",
      "--> Choose: 0\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "done = False\n",
    "counter = 1\n",
    "while not done:\n",
    "    print(\"\\n\"+str(counter)+\". Vehicle\\nPossible Actions for Lane \"+str(env.current_Lane)\n",
    "          +\"\\n\"+str(env.possible_actions))\n",
    "    source = []\n",
    "    for action in env.possible_actions:\n",
    "        source += [round(float(agent.predict(state,action)),2)]\n",
    "    best_action = agent.max_action(state,env.possible_actions)\n",
    "    \n",
    "    #print(env.possible_actions)\n",
    "    #source = DQN_agent.q_eval.predict(state[np.newaxis, :])\n",
    "    #best_action = DQN_agent.maxAction(state,env.possible_actions)\n",
    "    #print(\"Prediction of Agent:\\n\"+str(source[0][env.possible_actions]))\n",
    "    print(\"Prediction of Agent:\\n\"+str(source))\n",
    "    print(\"--> Choose: \"+str(best_action))\n",
    "    action = input() \n",
    "    try:\n",
    "        action = int(action)\n",
    "        if int(action) in env.possible_actions:\n",
    "            state, reward, done, info = env.step(int(action))\n",
    "            counter += 1            \n",
    "    except:\n",
    "        if action == 'b':\n",
    "            state, reward, done, info = env.step(int(best_action))\n",
    "            counter += 1\n",
    "        elif action == 'f':\n",
    "            #DQN_agent.execute(env)\n",
    "            agent.execute(env)\n",
    "            #agent.execute()\n",
    "            break\n",
    "        elif action == 'q':\n",
    "            print(\"Quit execution mode\")\n",
    "            break\n",
    "        elif action == 'r':\n",
    "            env.render()\n",
    "env.render()\n",
    "print(\"\\n\\n\")\n",
    "evaluation = evaluator.evaluate(env.get_stowage_plan())\n",
    "print(evaluation)\n",
    "print(\"\\n\\n\")\n",
    "print(env.loading_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
