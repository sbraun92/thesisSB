{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Stowage Planning with RL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Firstly various modules are imported (including agent classes, environment classes, a plotting unit and a logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "module_path = str(os.getcwd())+'\\\\out\\\\'\n",
    "\n",
    "from env import roroDeck\n",
    "from agent import sarsa, tdq, dqn\n",
    "from analysis import *\n",
    "from analysis.algorithms import *\n",
    "from analysis.evaluator import Evaluator\n",
    "from analysis.loggingUnit import LoggingBase\n",
    "\n",
    "\n",
    "from agent.tdq import TDQLearning\n",
    "from agent.sarsa import SARSA\n",
    "from agent.dqn import DQLearningAgent\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path is set to:\n",
      "C:\\Users\\braun\\Documents\\Masterarbeit\\analysis\\out\\\n"
     ]
    }
   ],
   "source": [
    "# Set relative path\n",
    "module_path = LoggingBase(prepare_training = False).module_path\n",
    "print('Path is set to:\\n'+module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a model and show input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: SARSA\n",
      "GAMMA: 0.999\n",
      "ALPHA: 0.1\n",
      "Episodes: 6000\n",
      "EnvLanes:: 8\n",
      "EnvRows: 12\n",
      "VehicleData: [[ 0  1  2  3  4]\n",
      " [ 5  5 -1 -1  2]\n",
      " [ 1  1  0  0  1]\n",
      " [ 1  2  1  2  2]\n",
      " [ 2  3  2  3  2]\n",
      " [ 0  0  0  0  1]]\n",
      "TrainingTime: 27.007267475128174\n"
     ]
    }
   ],
   "source": [
    "env = roroDeck.RoRoDeck()\n",
    "agent = tdq.TDQLearning(env,module_path)\n",
    "\n",
    "agent.load_model(module_path+\"20201118\\\\1927\\\\1927SARSA_L8-R12.p\")\n",
    "\n",
    "env = agent.env\n",
    "evaluator = Evaluator(env.vehicle_data, env.grid)\n",
    "\n",
    "\n",
    "for info in agent.q_table[\"ModelParam\"]:\n",
    "    print(info +': '+ str(agent.q_table[\"ModelParam\"][info]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = roroDeck.RoRoDeck()\n",
    "agent = sarsa.SARSA(env,module_path)\n",
    "\n",
    "agent.load_model(module_path+\"20200911\\\\1307\\\\1307TDQ_L8_R12_Rf1_A5.p\")\n",
    "\n",
    "env = agent.env\n",
    "evaluator = evm.Evaluator(env.vehicle_data, env.grid)\n",
    "\n",
    "\n",
    "for info in agent.q_table[\"ModelParam\"]:\n",
    "print(info +': '+ str(agent.q_table[\"ModelParam\"][info]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env = roroDeck.RoRoDeck(False,8,10)\n",
    "#evaluator = evm.Evaluator(env.vehicle_data, env.grid)\n",
    "#DQN_agent = DQNAgent(gamma=0.999, epsilon=1.0, alpha=0.0004, input_dims=np.shape(env.reset())[0], n_actions=5, mem_size=10000000, batch_size=32, epsilon_end=0.01, epsilon_dec= 0.999992)\n",
    "#DQN_agent.load_model(module_path+\"20200428\\\\1045\\\\104520200427stochasticdqn_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the best stowage plan the agent found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "#print(np.shape(env.current_state))\n",
    "#DQN_agent.execute(env)\n",
    "agent.execute(env)\n",
    "evaluation = evaluator.evaluate(env.get_stowage_plan())\n",
    "env.render()\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the loading sequence which constructed this stowage plan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.loading_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a stowage plan sequentially\n",
    "\n",
    "Example of a an human-agent interaction:\n",
    "Agent shows the predictions for each action in a given state and recommends the best one.\n",
    "If the Environment is set to deterministic behaviour the stowage plan above is reconstructed if all recommendations are obeyed\n",
    "\n",
    "Usage (Type the following on the Keyboard and press Enter):\n",
    "\n",
    "0,1,2 &nbsp; &nbsp; &nbsp; &nbsp; *number from the list of possible actions*\n",
    "\n",
    "r &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; *show the current state of the RORO-deck*\n",
    "\n",
    "b &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*follow the best action*\n",
    "\n",
    "f &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*stop interaction by only following the recommendations of agent*\n",
    "\n",
    "q &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;*quit the execution*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "done = False\n",
    "counter = 1\n",
    "while not done:\n",
    "    print(\"\\n\"+str(counter)+\". Vehicle\\nPossible Actions for Lane \"+str(env.current_Lane)\n",
    "          +\"\\n\"+str(env.possible_actions))\n",
    "    source = []\n",
    "    for action in env.possible_actions:\n",
    "        source += [round(float(agent.predict(state,action)),2)]\n",
    "    best_action = agent.max_action(state,env.possible_actions)\n",
    "    \n",
    "    #print(env.possible_actions)\n",
    "    #source = DQN_agent.q_eval.predict(state[np.newaxis, :])\n",
    "    #best_action = DQN_agent.maxAction(state,env.possible_actions)\n",
    "    #print(\"Prediction of Agent:\\n\"+str(source[0][env.possible_actions]))\n",
    "    print(\"Prediction of Agent:\\n\"+str(source))\n",
    "    print(\"--> Choose: \"+str(best_action))\n",
    "    action = input() \n",
    "    try:\n",
    "        action = int(action)\n",
    "        if int(action) in env.possible_actions:\n",
    "            state, reward, done, info = env.step(int(action))\n",
    "            counter += 1            \n",
    "    except:\n",
    "        if action == 'b':\n",
    "            state, reward, done, info = env.step(int(best_action))\n",
    "            counter += 1\n",
    "        elif action == 'f':\n",
    "            #DQN_agent.execute(env)\n",
    "            agent.execute(env)\n",
    "            #agent.execute()\n",
    "            break\n",
    "        elif action == 'q':\n",
    "            print(\"Quit execution mode\")\n",
    "            break\n",
    "        elif action == 'r':\n",
    "            env.render()\n",
    "env.render()\n",
    "print(\"\\n\\n\")\n",
    "evaluation = evaluator.evaluate(env.get_stowage_plan())\n",
    "print(evaluation)\n",
    "print(\"\\n\\n\")\n",
    "print(env.loading_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
